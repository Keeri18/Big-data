{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb0cf79",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-12T11:17:59.331720Z",
     "iopub.status.busy": "2022-04-12T11:17:59.330438Z",
     "iopub.status.idle": "2022-04-12T11:17:59.341760Z",
     "shell.execute_reply": "2022-04-12T11:17:59.342328Z",
     "shell.execute_reply.started": "2022-04-12T11:09:20.570107Z"
    },
    "papermill": {
     "duration": 0.044628,
     "end_time": "2022-04-12T11:17:59.342646",
     "exception": false,
     "start_time": "2022-04-12T11:17:59.298018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d2b99a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:17:59.404076Z",
     "iopub.status.busy": "2022-04-12T11:17:59.403351Z",
     "iopub.status.idle": "2022-04-12T11:18:49.959739Z",
     "shell.execute_reply": "2022-04-12T11:18:49.958983Z",
     "shell.execute_reply.started": "2022-04-12T11:09:20.811600Z"
    },
    "papermill": {
     "duration": 50.587661,
     "end_time": "2022-04-12T11:18:49.959897",
     "exception": false,
     "start_time": "2022-04-12T11:17:59.372236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\r\n",
      "     |████████████████████████████████| 281.4 MB 31 kB/s              \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting py4j==0.10.9.3\r\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\r\n",
      "     |████████████████████████████████| 198 kB 54.0 MB/s            \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=35edc34be04123006f4dfb050423afe744a3a923bda2229a8c5f61108210d0e1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "  Attempting uninstall: py4j\r\n",
      "    Found existing installation: py4j 0.10.9.4\r\n",
      "    Uninstalling py4j-0.10.9.4:\r\n",
      "      Successfully uninstalled py4j-0.10.9.4\r\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799b73b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:18:50.349023Z",
     "iopub.status.busy": "2022-04-12T11:18:50.348312Z",
     "iopub.status.idle": "2022-04-12T11:19:00.229954Z",
     "shell.execute_reply": "2022-04-12T11:19:00.229227Z",
     "shell.execute_reply.started": "2022-04-12T11:09:28.381199Z"
    },
    "papermill": {
     "duration": 10.081727,
     "end_time": "2022-04-12T11:19:00.230098",
     "exception": false,
     "start_time": "2022-04-12T11:18:50.148371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\r\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\r\n",
      "Installing collected packages: findspark\r\n",
      "Successfully installed findspark-2.0.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7cd7379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:00.612347Z",
     "iopub.status.busy": "2022-04-12T11:19:00.611579Z",
     "iopub.status.idle": "2022-04-12T11:19:05.877125Z",
     "shell.execute_reply": "2022-04-12T11:19:05.877681Z",
     "shell.execute_reply.started": "2022-04-12T11:09:35.971394Z"
    },
    "papermill": {
     "duration": 5.461061,
     "end_time": "2022-04-12T11:19:05.877858",
     "exception": false,
     "start_time": "2022-04-12T11:19:00.416797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/12 11:19:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "#from pyspark import SparkContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql.functions import trim, to_date, year, month\n",
    "from pyspark import SparkContext, SparkConf\n",
    "#conf = SparkConf().setAppName(\"pyspark\")\n",
    "#sc = SparkContext(conf=conf)\n",
    "#sc= SparkContext().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803ec69b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:06.260086Z",
     "iopub.status.busy": "2022-04-12T11:19:06.259019Z",
     "iopub.status.idle": "2022-04-12T11:19:12.211529Z",
     "shell.execute_reply": "2022-04-12T11:19:12.212689Z",
     "shell.execute_reply.started": "2022-04-12T11:09:35.982212Z"
    },
    "papermill": {
     "duration": 6.146761,
     "end_time": "2022-04-12T11:19:12.213052",
     "exception": false,
     "start_time": "2022-04-12T11:19:06.066291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|Seqno|Name        |\n",
      "+-----+------------+\n",
      "|1    |john jones  |\n",
      "|2    |tracey smith|\n",
      "|3    |amy sanders |\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "columns = [\"Seqno\",\"Name\"]\n",
    "data = [(\"1\", \"john jones\"),\n",
    "    (\"2\", \"tracey smith\"),\n",
    "    (\"3\", \"amy sanders\")]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802d2bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:12.613481Z",
     "iopub.status.busy": "2022-04-12T11:19:12.612785Z",
     "iopub.status.idle": "2022-04-12T11:19:12.615207Z",
     "shell.execute_reply": "2022-04-12T11:19:12.615742Z",
     "shell.execute_reply.started": "2022-04-12T11:09:36.190569Z"
    },
    "papermill": {
     "duration": 0.21029,
     "end_time": "2022-04-12T11:19:12.615980",
     "exception": false,
     "start_time": "2022-04-12T11:19:12.405690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convertCase(str):\n",
    "    resStr=\"\"\n",
    "    arr = str.split(\" \")\n",
    "    for x in arr:\n",
    "        resStr= resStr + x[0:1].upper() + x[1:len(x)] + \" \"\n",
    "    return resStr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd45c12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:12.993623Z",
     "iopub.status.busy": "2022-04-12T11:19:12.992943Z",
     "iopub.status.idle": "2022-04-12T11:19:12.999194Z",
     "shell.execute_reply": "2022-04-12T11:19:12.998518Z",
     "shell.execute_reply.started": "2022-04-12T11:09:36.197130Z"
    },
    "papermill": {
     "duration": 0.198977,
     "end_time": "2022-04-12T11:19:12.999331",
     "exception": false,
     "start_time": "2022-04-12T11:19:12.800354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Converting function to UDF \"\"\"\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, IntegerType, StringType\n",
    "convertUDF = udf(lambda z: convertCase(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c309246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:13.379638Z",
     "iopub.status.busy": "2022-04-12T11:19:13.378926Z",
     "iopub.status.idle": "2022-04-12T11:19:13.381725Z",
     "shell.execute_reply": "2022-04-12T11:19:13.381205Z",
     "shell.execute_reply.started": "2022-04-12T11:09:36.212606Z"
    },
    "papermill": {
     "duration": 0.195723,
     "end_time": "2022-04-12T11:19:13.381882",
     "exception": false,
     "start_time": "2022-04-12T11:19:13.186159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Converting function to UDF \n",
    "StringType() is by default hence not required \"\"\"\n",
    "convertUDF = udf(lambda z: convertCase(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c134e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:13.761957Z",
     "iopub.status.busy": "2022-04-12T11:19:13.761232Z",
     "iopub.status.idle": "2022-04-12T11:19:15.063148Z",
     "shell.execute_reply": "2022-04-12T11:19:15.061437Z",
     "shell.execute_reply.started": "2022-04-12T11:09:36.231423Z"
    },
    "papermill": {
     "duration": 1.494628,
     "end_time": "2022-04-12T11:19:15.063442",
     "exception": false,
     "start_time": "2022-04-12T11:19:13.568814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|Seqno|Name         |\n",
      "+-----+-------------+\n",
      "|1    |John Jones   |\n",
      "|2    |Tracey Smith |\n",
      "|3    |Amy Sanders  |\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"Seqno\"), \\\n",
    "    convertUDF(col(\"Name\")).alias(\"Name\") ) \\\n",
    "   .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c4a11dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:15.590953Z",
     "iopub.status.busy": "2022-04-12T11:19:15.590210Z",
     "iopub.status.idle": "2022-04-12T11:19:15.594153Z",
     "shell.execute_reply": "2022-04-12T11:19:15.595030Z",
     "shell.execute_reply.started": "2022-04-12T11:09:36.463600Z"
    },
    "papermill": {
     "duration": 0.218967,
     "end_time": "2022-04-12T11:19:15.595261",
     "exception": false,
     "start_time": "2022-04-12T11:19:15.376294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upperCase(str):\n",
    "    return str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc33983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:15.989423Z",
     "iopub.status.busy": "2022-04-12T11:19:15.988713Z",
     "iopub.status.idle": "2022-04-12T11:19:16.437330Z",
     "shell.execute_reply": "2022-04-12T11:19:16.436170Z",
     "shell.execute_reply.started": "2022-04-12T11:09:36.471547Z"
    },
    "papermill": {
     "duration": 0.638951,
     "end_time": "2022-04-12T11:19:16.437573",
     "exception": false,
     "start_time": "2022-04-12T11:19:15.798622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-------------+\n",
      "|Seqno|Name        |Cureated Name|\n",
      "+-----+------------+-------------+\n",
      "|1    |john jones  |JOHN JONES   |\n",
      "|2    |tracey smith|TRACEY SMITH |\n",
      "|3    |amy sanders |AMY SANDERS  |\n",
      "+-----+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upperCaseUDF = udf(lambda z:upperCase(z),StringType())   \n",
    "\n",
    "df.withColumn(\"Cureated Name\", upperCaseUDF(col(\"Name\"))) \\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "163e93fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:17.004441Z",
     "iopub.status.busy": "2022-04-12T11:19:17.003322Z",
     "iopub.status.idle": "2022-04-12T11:19:17.579504Z",
     "shell.execute_reply": "2022-04-12T11:19:17.580257Z",
     "shell.execute_reply.started": "2022-04-12T11:09:36.689450Z"
    },
    "papermill": {
     "duration": 0.843066,
     "end_time": "2022-04-12T11:19:17.580518",
     "exception": false,
     "start_time": "2022-04-12T11:19:16.737452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|Seqno|Name         |\n",
      "+-----+-------------+\n",
      "|1    |John Jones   |\n",
      "|2    |Tracey Smith |\n",
      "|3    |Amy Sanders  |\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Using UDF on SQL \"\"\"\n",
    "spark.udf.register(\"convertUDF\", convertCase,StringType())\n",
    "df.createOrReplaceTempView(\"NAME_TABLE\")\n",
    "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE\") \\\n",
    "     .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "864760af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:18.135722Z",
     "iopub.status.busy": "2022-04-12T11:19:18.135059Z",
     "iopub.status.idle": "2022-04-12T11:19:18.566507Z",
     "shell.execute_reply": "2022-04-12T11:19:18.565556Z",
     "shell.execute_reply.started": "2022-04-12T11:09:36.952896Z"
    },
    "papermill": {
     "duration": 0.734187,
     "end_time": "2022-04-12T11:19:18.566702",
     "exception": false,
     "start_time": "2022-04-12T11:19:17.832515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-------------+\n",
      "|Seqno|Name        |Cureated Name|\n",
      "+-----+------------+-------------+\n",
      "|1    |john jones  |JOHN JONES   |\n",
      "|2    |tracey smith|TRACEY SMITH |\n",
      "|3    |amy sanders |AMY SANDERS  |\n",
      "+-----+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf(returnType=StringType()) \n",
    "def upperCase(str):\n",
    "    return str.upper()\n",
    "\n",
    "df.withColumn(\"Cureated Name\", upperCase(col(\"Name\"))) \\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14a4c93b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:19.045553Z",
     "iopub.status.busy": "2022-04-12T11:19:19.044693Z",
     "iopub.status.idle": "2022-04-12T11:19:19.603838Z",
     "shell.execute_reply": "2022-04-12T11:19:19.602118Z",
     "shell.execute_reply.started": "2022-04-12T11:09:37.212026Z"
    },
    "papermill": {
     "duration": 0.775949,
     "end_time": "2022-04-12T11:19:19.604222",
     "exception": false,
     "start_time": "2022-04-12T11:19:18.828273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|Seqno|Name       |\n",
      "+-----+-----------+\n",
      "|1    |John Jones |\n",
      "+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "No guarantee Name is not null will execute first\n",
    "If convertUDF(Name) like '%John%' execute first then \n",
    "you will get runtime error\n",
    "\"\"\"\n",
    "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE \" + \"where Name is not null and convertUDF(Name) like '%John%'\").show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a42b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:20.136489Z",
     "iopub.status.busy": "2022-04-12T11:19:20.135342Z",
     "iopub.status.idle": "2022-04-12T11:19:20.347349Z",
     "shell.execute_reply": "2022-04-12T11:19:20.346301Z",
     "shell.execute_reply.started": "2022-04-12T11:10:35.094241Z"
    },
    "papermill": {
     "duration": 0.435058,
     "end_time": "2022-04-12T11:19:20.347578",
     "exception": false,
     "start_time": "2022-04-12T11:19:19.912520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|Seqno|Name        |\n",
      "+-----+------------+\n",
      "|1    |john jones  |\n",
      "|2    |tracey smith|\n",
      "|3    |amy sanders |\n",
      "|4    |null        |\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" null check \"\"\"\n",
    "\n",
    "columns = [\"Seqno\",\"Name\"]\n",
    "data = [(\"1\", \"john jones\"),\n",
    "    (\"2\", \"tracey smith\"),\n",
    "    (\"3\", \"amy sanders\"),\n",
    "    ('4',None)]\n",
    "\n",
    "df2 = spark.createDataFrame(data=data,schema=columns)\n",
    "df2.show(truncate=False)\n",
    "df2.createOrReplaceTempView(\"NAME_TABLE2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b239cc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:20.763255Z",
     "iopub.status.busy": "2022-04-12T11:19:20.762515Z",
     "iopub.status.idle": "2022-04-12T11:19:21.598007Z",
     "shell.execute_reply": "2022-04-12T11:19:21.597086Z",
     "shell.execute_reply.started": "2022-04-12T11:13:40.149337Z"
    },
    "papermill": {
     "duration": 1.029564,
     "end_time": "2022-04-12T11:19:21.598218",
     "exception": false,
     "start_time": "2022-04-12T11:19:20.568654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|_nullsafeUDF(Name)|\n",
      "+------------------+\n",
      "|John Jones        |\n",
      "|Tracey Smith      |\n",
      "|Amy Sanders       |\n",
      "|                  |\n",
      "+------------------+\n",
      "\n",
      "+-----+-----------+\n",
      "|Seqno|Name       |\n",
      "+-----+-----------+\n",
      "|1    |John Jones |\n",
      "+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.udf.register(\"_nullsafeUDF\", lambda str: convertCase(str) if not str is None else \"\" , StringType())\n",
    "\n",
    "spark.sql(\"select _nullsafeUDF(Name) from NAME_TABLE2\") \\\n",
    "     .show(truncate=False)\n",
    "\n",
    "spark.sql(\"select Seqno, _nullsafeUDF(Name) as Name from NAME_TABLE2 \" + \\\n",
    "          \" where Name is not null and _nullsafeUDF(Name) like '%John%'\") \\\n",
    "     .show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fdf820",
   "metadata": {
    "papermill": {
     "duration": 0.189198,
     "end_time": "2022-04-12T11:19:22.009168",
     "exception": false,
     "start_time": "2022-04-12T11:19:21.819970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2ecbc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:22.392955Z",
     "iopub.status.busy": "2022-04-12T11:19:22.392251Z",
     "iopub.status.idle": "2022-04-12T11:19:22.570037Z",
     "shell.execute_reply": "2022-04-12T11:19:22.568479Z",
     "shell.execute_reply.started": "2022-04-12T11:14:00.211362Z"
    },
    "papermill": {
     "duration": 0.373311,
     "end_time": "2022-04-12T11:19:22.570414",
     "exception": false,
     "start_time": "2022-04-12T11:19:22.197103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  Name|RawScore|\n",
      "+------+--------+\n",
      "|  Jack|      79|\n",
      "|  Mira|      80|\n",
      "|Carter|      90|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType,StringType, FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "  \n",
    "spark = SparkSession.builder.appName('UDF PRACTICE').getOrCreate()\n",
    "  \n",
    "cms = [\"Name\",\"RawScore\"]\n",
    "data =  [(\"Jack\", \"79\"),\n",
    "        (\"Mira\", \"80\"),\n",
    "        (\"Carter\", \"90\")]\n",
    "                     \n",
    "df = spark.createDataFrame(data=data,schema=cms)\n",
    "  \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "674b09c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:22.956665Z",
     "iopub.status.busy": "2022-04-12T11:19:22.955895Z",
     "iopub.status.idle": "2022-04-12T11:19:22.957349Z",
     "shell.execute_reply": "2022-04-12T11:19:22.957936Z",
     "shell.execute_reply.started": "2022-04-12T11:14:02.454762Z"
    },
    "papermill": {
     "duration": 0.197839,
     "end_time": "2022-04-12T11:19:22.958104",
     "exception": false,
     "start_time": "2022-04-12T11:19:22.760265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Converter(str):\n",
    "    result = \"\"\n",
    "    a = str.split(\" \")\n",
    "      \n",
    "    for q in a:\n",
    "        if q == 'J' or 'C' or 'M':\n",
    "            result += q[1:2].upper()\n",
    "              \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c6514d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:23.352076Z",
     "iopub.status.busy": "2022-04-12T11:19:23.350947Z",
     "iopub.status.idle": "2022-04-12T11:19:23.353089Z",
     "shell.execute_reply": "2022-04-12T11:19:23.353850Z",
     "shell.execute_reply.started": "2022-04-12T11:14:05.141307Z"
    },
    "papermill": {
     "duration": 0.204161,
     "end_time": "2022-04-12T11:19:23.354112",
     "exception": false,
     "start_time": "2022-04-12T11:19:23.149951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NumberUDF = udf(lambda m: Converter(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0c831cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:23.749008Z",
     "iopub.status.busy": "2022-04-12T11:19:23.746843Z",
     "iopub.status.idle": "2022-04-12T11:19:24.050232Z",
     "shell.execute_reply": "2022-04-12T11:19:24.049170Z",
     "shell.execute_reply.started": "2022-04-12T11:14:08.040185Z"
    },
    "papermill": {
     "duration": 0.499119,
     "end_time": "2022-04-12T11:19:24.050442",
     "exception": false,
     "start_time": "2022-04-12T11:19:23.551323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+\n",
      "|  Name|RawScore|Special Names|\n",
      "+------+--------+-------------+\n",
      "|  Jack|      79|            A|\n",
      "|  Mira|      80|            I|\n",
      "|Carter|      90|            A|\n",
      "+------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Special Names\", NumberUDF(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4136666e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:24.486962Z",
     "iopub.status.busy": "2022-04-12T11:19:24.486236Z",
     "iopub.status.idle": "2022-04-12T11:19:24.755056Z",
     "shell.execute_reply": "2022-04-12T11:19:24.753989Z",
     "shell.execute_reply.started": "2022-04-12T11:14:14.219492Z"
    },
    "papermill": {
     "duration": 0.467978,
     "end_time": "2022-04-12T11:19:24.755263",
     "exception": false,
     "start_time": "2022-04-12T11:19:24.287285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+\n",
      "|  Name|RawScore|Special Names|\n",
      "+------+--------+-------------+\n",
      "|  Jack|      79|            A|\n",
      "|  Mira|      80|            I|\n",
      "|Carter|      90|            A|\n",
      "+------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf(returnType=StringType())\n",
    "def Converter(str):\n",
    "    result = \"\"\n",
    "    a = str.split(\" \")\n",
    "  \n",
    "    for q in a:\n",
    "        if q == 'J' or 'C' or 'M':\n",
    "            result += q[1:2].upper()\n",
    "        else:\n",
    "            result += q\n",
    "    return result\n",
    "  \n",
    "  \n",
    "df.withColumn(\"Special Names\", Converter(\"Name\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7ab81",
   "metadata": {
    "papermill": {
     "duration": 0.241288,
     "end_time": "2022-04-12T11:19:25.307341",
     "exception": false,
     "start_time": "2022-04-12T11:19:25.066053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c564be92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:25.692745Z",
     "iopub.status.busy": "2022-04-12T11:19:25.692118Z",
     "iopub.status.idle": "2022-04-12T11:19:25.694406Z",
     "shell.execute_reply": "2022-04-12T11:19:25.694834Z",
     "shell.execute_reply.started": "2022-04-12T11:14:24.726884Z"
    },
    "papermill": {
     "duration": 0.197477,
     "end_time": "2022-04-12T11:19:25.695033",
     "exception": false,
     "start_time": "2022-04-12T11:19:25.497556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def SQRT(x):\n",
    "    return float(math.sqrt(x)+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d85bebc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:26.087573Z",
     "iopub.status.busy": "2022-04-12T11:19:26.086861Z",
     "iopub.status.idle": "2022-04-12T11:19:26.090290Z",
     "shell.execute_reply": "2022-04-12T11:19:26.089621Z",
     "shell.execute_reply.started": "2022-04-12T11:16:19.291279Z"
    },
    "papermill": {
     "duration": 0.204063,
     "end_time": "2022-04-12T11:19:26.090430",
     "exception": false,
     "start_time": "2022-04-12T11:19:25.886367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "UDF_marks = udf(lambda m: SQRT(int(m)),FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "440325d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T11:19:26.481705Z",
     "iopub.status.busy": "2022-04-12T11:19:26.481060Z",
     "iopub.status.idle": "2022-04-12T11:19:26.822774Z",
     "shell.execute_reply": "2022-04-12T11:19:26.821821Z",
     "shell.execute_reply.started": "2022-04-12T11:16:24.276345Z"
    },
    "papermill": {
     "duration": 0.538941,
     "end_time": "2022-04-12T11:19:26.822997",
     "exception": false,
     "start_time": "2022-04-12T11:19:26.284056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+\n",
      "|  Name|RawScore|<lambda>(RawScore)|\n",
      "+------+--------+------------------+\n",
      "|  Jack|      79|         11.888194|\n",
      "|  Mira|      80|         11.944272|\n",
      "|Carter|      90|         12.486833|\n",
      "+------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Name\",\"RawScore\", UDF_marks(\"RawScore\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050cf194",
   "metadata": {
    "papermill": {
     "duration": 0.193267,
     "end_time": "2022-04-12T11:19:27.268729",
     "exception": false,
     "start_time": "2022-04-12T11:19:27.075462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://sparkbyexamples.com/pyspark/pyspark-udf-user-defined-function/\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-write-spark-udf-user-defined-functions-in-python/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324345b6",
   "metadata": {
    "papermill": {
     "duration": 0.191626,
     "end_time": "2022-04-12T11:19:27.663008",
     "exception": false,
     "start_time": "2022-04-12T11:19:27.471382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 99.950169,
   "end_time": "2022-04-12T11:19:28.568061",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-12T11:17:48.617892",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
